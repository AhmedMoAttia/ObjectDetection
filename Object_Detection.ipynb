{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNA5qiRSuEocZN7/kuolDDL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sc-AhmedAttia/ObjectDetection/blob/main/Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTKJxwzuuNiJ"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/{ssd,yolo} tools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tools/__init__.py\n",
        "# init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o8CMOdxvZ56",
        "outputId": "d6789d61-fe1d-49fd-b887-f80128ee4569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tools/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env KAGGLE_USERNAME=datadinosaur\n",
        "%env KAGGLE_KEY=xxxxxxxxxxxxxx"
      ],
      "metadata": {
        "id": "fmkbBlF1wIGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d chetankv/dogs-cats-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQjHogFeRBdY",
        "outputId": "f2e97cc2-a5d5-4792-c015-bde272816a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-cats-images.zip to /content\n",
            " 98% 427M/435M [00:03<00:00, 117MB/s]\n",
            "100% 435M/435M [00:03<00:00, 120MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq dogs-cats-images.zip"
      ],
      "metadata": {
        "id": "9HzdimVQRE4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/dog vs cat\""
      ],
      "metadata": {
        "id": "Em0h9XhtROvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm dogs-cats-images.zip"
      ],
      "metadata": {
        "id": "7_zcmy6nSUDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tools/config.py\n",
        "# import the necessary packages\n",
        "import torch\n",
        "import os\n",
        "# define the root directory followed by the test dataset paths\n",
        "BASE_PATH = \"dataset\"\n",
        "TEST_PATH = os.path.join(BASE_PATH, \"test_set\")\n",
        "# specify image size and batch size\n",
        "IMAGE_SIZE = 300\n",
        "PRED_BATCH_SIZE = 4\n",
        "# specify threshold confidence value for ssd detections\n",
        "THRESHOLD = 0.50\n",
        "# determine the device type \n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
        "# define paths to save output \n",
        "OUTPUT_PATH = \"output\"\n",
        "SSD_OUTPUT = os.path.join(OUTPUT_PATH, \"ssd\")\n",
        "YOLO_OUTPUT = os.path.join(OUTPUT_PATH, \"yolo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1c7K5u9Syxw",
        "outputId": "db2c878c-8900-4a4e-e8e2-d60fe4d61afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tools/config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tools/data_utils.py\n",
        "# import the necessary packages\n",
        "from torch.utils.data import DataLoader\n",
        "def get_dataloader(dataset, batchSize, shuffle=True):\n",
        "\t# create a dataloader and return it\n",
        "\tdataLoader= DataLoader(dataset, batch_size=batchSize,\n",
        "\t\tshuffle=shuffle)\n",
        "\treturn dataLoader\n",
        "\n",
        "def normalize(image, mean=128, std=128):\n",
        "    # normalize the SSD input and return it \n",
        "    image = (image * 256 - mean) / std\n",
        "    return image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAJ88naUTOkE",
        "outputId": "0fd14516-ebdc-4a87-e9db-66d09532c2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tools/data_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary packages\n",
        "from tools.data_utils import get_dataloader\n",
        "import tools.config as config\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "# initialize test transform pipeline\n",
        "testTransform = Compose([\n",
        "\tResize((config.IMAGE_SIZE, config.IMAGE_SIZE)), ToTensor()])\n",
        "# create the test dataset\n",
        "testDataset = ImageFolder(config.TEST_PATH, testTransform)\n",
        "# initialize the test data loader\n",
        "testLoader = get_dataloader(testDataset, config.PRED_BATCH_SIZE)"
      ],
      "metadata": {
        "id": "4ESkB0exTqt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the yolov5 using torch hub\n",
        "yoloModel = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
        "# initialize iterable variable\n",
        "sweeper = iter(testLoader)\n",
        "# initialize image \n",
        "imageInput = []\n",
        "# grab a batch of test data\n",
        "print(\"[INFO] getting the test data...\")\n",
        "batch = next(sweeper)\n",
        "(images, _) = (batch[0], batch[1])\n",
        "# send the images to the device\n",
        "images = images.to(config.DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nru3J9qhT6Gi",
        "outputId": "c2a3c8a8-6eb3-4ca5-9a38-be1a6fdda1fc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m PyYAML>=5.3.1 not found and is required by YOLOv5, attempting auto-update...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ 2022-1-5 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] getting the test data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over all the batch \n",
        "for index in range(0, config.PRED_BATCH_SIZE):\n",
        "\t# grab each image\n",
        "\t# rearrange dimensions to channel last and\n",
        "\t# append them to image list\n",
        "\timage = images[index]\n",
        "\timage = image.permute((1, 2, 0))\n",
        "\timageInput.append(image.cpu().detach().numpy()*255.0)\n",
        "# pass the image list through the model\n",
        "print(\"[INFO] getting detections from the test data...\")\n",
        "results = yoloModel(imageInput, size=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBbhjGYnUGsy",
        "outputId": "88c47c42-5e53-4741-ad7a-3aa140b65de3"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] getting detections from the test data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get random index value\n",
        "randomIndex = random.randint(0,len(imageInput)-1)\n",
        "# grab index result from results variable\n",
        "imageIndex= results.pandas().xyxy[randomIndex]\n",
        "# convert the bounding box values to integer\n",
        "startX = int(imageIndex[\"xmin\"][0])\n",
        "startY = int(imageIndex[\"ymin\"][0])\n",
        "endX = int(imageIndex[\"xmax\"][0])\n",
        "endY = int(imageIndex[\"ymax\"][0])\n",
        "# draw the predicted bounding box and class label on the image\n",
        "y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "cv2.putText(imageInput[randomIndex], imageIndex[\"name\"][0],\n",
        "\t(startX, y+10), cv2.FONT_HERSHEY_SIMPLEX,0.65, (0, 255, 0), 2)\n",
        "cv2.rectangle(imageInput[randomIndex],\n",
        "\t(startX, startY), (endX, endY),(0, 255, 0), 2)\n",
        "# check to see if the output directory already exists, if not\n",
        "# make the output directory\n",
        "if not os.path.exists(config.YOLO_OUTPUT):\n",
        "    os.makedirs(config.YOLO_OUTPUT)\n",
        "# show the output image and save it to path\n",
        "plt.imshow(imageInput[randomIndex]/255.0)\n",
        "# save plots to output directory\n",
        "print(\"[INFO] saving the inference...\")\n",
        "outputFileName = os.path.join(config.YOLO_OUTPUT, \"output.png\")\n",
        "plt.savefig(outputFileName)\n",
        "plt.clf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mDdRga3VCwi",
        "outputId": "8bb25a3b-fab9-4342-e362-6598010290d1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] saving the inference...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tools.data_utils import normalize\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "imageInput = []"
      ],
      "metadata": {
        "id": "HP_K1_FBVna1"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab a batch of test data\n",
        "print(\"[INFO] getting the test data...\")\n",
        "\n",
        "# switch off autograd\n",
        "with torch.no_grad():\n",
        "\t# loop over all the batch \n",
        "\tfor index in range(0, config.PRED_BATCH_SIZE):\n",
        "\t\t# grab the image, de-normalize it, scale the raw pixel\n",
        "\t\t# intensities to the range [0, 255], and change the channel\n",
        "\t\t# ordering from channels first tp channels last\n",
        "\t\timage = images[index]\n",
        "\t\timage = image.permute((1, 2, 0))\n",
        "\t\timageInput.append(image.cpu().detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "behnYUN1Zkdg",
        "outputId": "2e8f4dc9-d9ae-4395-9c20-da13d81cccf6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] getting the test data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call the required entry points\n",
        "ssdModel = torch.hub.load(\"NVIDIA/DeepLearningExamples:torchhub\",\n",
        "\t\"nvidia_ssd\")\n",
        "utils = torch.hub.load(\"NVIDIA/DeepLearningExamples:torchhub\", \n",
        "\t\"nvidia_ssd_processing_utils\")\n",
        "# flash model to the device and set it to eval mode\n",
        "ssdModel.to(config.DEVICE)\n",
        "ssdModel.eval()\n",
        "# new list for processed input\n",
        "processedInput = []\n",
        "# loop over images and preprocess them\n",
        "for image in imageInput:\n",
        "\timage = normalize (image)\n",
        "\tprocessedInput.append(image)\n",
        "# convert the preprocessed images into tensors\n",
        "inputTensor = utils.prepare_tensor(processedInput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pc25eFyZ73s",
        "outputId": "c9a46df4-4d38-4bf1-9b47-5b79c4334990"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# turn off auto-grad\n",
        "print(\"[INFO] getting detections from the test data...\")\n",
        "with torch.no_grad():\n",
        "\t# feed images to model\n",
        "\tdetections = ssdModel(inputTensor)\n",
        "# decode the results and filter them using the threshold\n",
        "resultsPerInput = utils.decode_results(detections)\n",
        "bestResults = [utils.pick_best(results,\n",
        "\tconfig.THRESHOLD) for results in resultsPerInput]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7D4JbELbbcF",
        "outputId": "ae37aab8-4e00-4a2b-c3b9-c0b7826e495d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] getting detections from the test data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get coco labels \n",
        "classesToLabels = utils.get_coco_object_dictionary()\n",
        "# loop over the image batch\n",
        "for image_idx in range(len(bestResults)):\n",
        "\t(fig, ax) = plt.subplots(1)\n",
        "\t# denormalize the image and plot the image\n",
        "\timage = processedInput[image_idx] / 2 + 0.5\n",
        "\tax.imshow(image)\n",
        "\t# grab bbox, class, and confidence values\n",
        "\t(bboxes, classes, confidences) = bestResults[image_idx]\n",
        "\n",
        "\t# loop over the detected bounding boxes\n",
        "\tfor idx in range(len(bboxes)):\n",
        "\t\t# scale values up according to image size\n",
        "\t\t(left, bot, right, top) = bboxes[idx ] * 300\n",
        "\t\t# draw the bounding box on the image\n",
        "\t\t(x, y, w, h) = [val for val in [left, bot, right - left,\n",
        "\t\t\ttop - bot]]\n",
        "\t\trect = patches.Rectangle((x, y), w, h, linewidth=1,\n",
        "\t\t\tedgecolor=\"r\", facecolor=\"none\")\n",
        "\t\tax.add_patch(rect)\n",
        "\t\tax.text(x, y,\n",
        "\t\t\t\"{} {:.0f}%\".format(classesToLabels[classes[idx] - 1],\n",
        "\t\t\tconfidences[idx] * 100),\n",
        "\t\t\tbbox=dict(facecolor=\"white\", alpha=0.5))\n",
        "\t\n",
        "\t# check to see if the output directory already exists, if not\n",
        "\t# make the output directory\n",
        "\tif not os.path.exists(config.SSD_OUTPUT):\n",
        "\t\tos.makedirs(config.SSD_OUTPUT)\n",
        "\t# save plots to output directory\n",
        "\tprint(\"[INFO] saving the inference {}...\".format(image_idx))\n",
        "\toutputFileName = os.path.join(config.SSD_OUTPUT, \"output{}.png\".format(image_idx))\n",
        "\tplt.savefig(outputFileName)\n",
        "\tplt.clf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZQQKoHcccpW",
        "outputId": "04338deb-66e4-4eec-a136-4bbdecc3f721"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] saving the inference 0...\n",
            "[INFO] saving the inference 1...\n",
            "[INFO] saving the inference 2...\n",
            "[INFO] saving the inference 3...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjFNQ7NAcsox",
        "outputId": "956a4be7-0667-4b6d-840d-44fe0467d8a6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".   category_names.txt\tdataset  sample_data  yolov5s.pt\n",
            "..  .config\t\toutput\t tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository -y ppa:git-core/ppa\n",
        "!sudo apt update\n",
        "!sudo apt install git -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sTmSzo2fgvR",
        "outputId": "aeaba94b-53ef-45fd-80c4-0b6e7d10d03b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.8 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,459 kB]\n",
            "Hit:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,489 kB]\n",
            "Get:18 http://ppa.launchpad.net/git-core/ppa/ubuntu bionic InRelease [20.8 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [716 kB]\n",
            "Get:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,822 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [749 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.5 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,927 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,238 kB]\n",
            "Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:28 http://ppa.launchpad.net/git-core/ppa/ubuntu bionic/main amd64 Packages [4,531 B]\n",
            "Get:29 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.7 kB]\n",
            "Fetched 13.7 MB in 4s (3,268 kB/s)\n",
            "Reading package lists... Done\n",
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/git-core/ppa/ubuntu bionic InRelease\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "61 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  git-man\n",
            "Suggested packages:\n",
            "  gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-email git-gui\n",
            "  gitk gitweb git-cvs git-mediawiki git-svn\n",
            "The following packages will be upgraded:\n",
            "  git git-man\n",
            "2 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 7,610 kB of archives.\n",
            "After this operation, 6,132 kB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/git-core/ppa/ubuntu bionic/main amd64 git amd64 1:2.34.1-0ppa1~ubuntu18.04.1 [5,710 kB]\n",
            "Get:2 http://ppa.launchpad.net/git-core/ppa/ubuntu bionic/main amd64 git-man all 1:2.34.1-0ppa1~ubuntu18.04.1 [1,901 kB]\n",
            "Fetched 7,610 kB in 2s (3,898 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 155225 files and directories currently installed.)\n",
            "Preparing to unpack .../git_1%3a2.34.1-0ppa1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking git (1:2.34.1-0ppa1~ubuntu18.04.1) over (1:2.17.1-1ubuntu0.9) ...\n",
            "Preparing to unpack .../git-man_1%3a2.34.1-0ppa1~ubuntu18.04.1_all.deb ...\n",
            "Unpacking git-man (1:2.34.1-0ppa1~ubuntu18.04.1) over (1:2.17.1-1ubuntu0.9) ...\n",
            "Setting up git-man (1:2.34.1-0ppa1~ubuntu18.04.1) ...\n",
            "Setting up git (1:2.34.1-0ppa1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"my_email\"\n",
        "!git config --global user.name \"my_user\""
      ],
      "metadata": {
        "id": "R1jPbcSHng84"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git init -b main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YOkfFGCn1O9",
        "outputId": "0349847a-971e-4b0b-fbbc-670d455a2bcf"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://<USERNAME>:<Token>@github.com/<USERNAME>/reponame.git"
      ],
      "metadata": {
        "id": "F6vB8NO3oAF9"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote -v"
      ],
      "metadata": {
        "id": "S9bTPqPZoSnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_hgNv7MoW5H",
        "outputId": "1bb09025-5d40-4484-b9e1-8b33e4b5d4eb"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)\u001b[K\rremote: Counting objects:  50% (2/4)\u001b[K\rremote: Counting objects:  75% (3/4)\u001b[K\rremote: Counting objects: 100% (4/4)\u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 1.56 KiB | 801.00 KiB/s, done.\n",
            "From https://github.com/sc-AhmedAttia/ObjectDetection\n",
            " * branch            main       -> FETCH_HEAD\n",
            " * [new branch]      main       -> origin/main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add output/ tools/ category_names.txt"
      ],
      "metadata": {
        "id": "4i8iogQBobJB"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Implementation\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kteb56lmoo3U",
        "outputId": "e8c79018-1e5d-447a-92a5-ad6281ae0f2d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main a5fd253] Implementation\n",
            " 12 files changed, 110 insertions(+)\n",
            " create mode 100644 category_names.txt\n",
            " create mode 100644 output/ssd/output0.png\n",
            " create mode 100644 output/ssd/output1.png\n",
            " create mode 100644 output/ssd/output2.png\n",
            " create mode 100644 output/ssd/output3.png\n",
            " create mode 100644 output/yolo/output.png\n",
            " create mode 100644 output/yolo/output_semi0.png\n",
            " create mode 100644 output/yolo/output_semi1.png\n",
            " create mode 100644 output/yolo/output_wrong.png\n",
            " create mode 100644 tools/__init__.py\n",
            " create mode 100644 tools/config.py\n",
            " create mode 100644 tools/data_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3jug1ESorko",
        "outputId": "41fab87d-f18d-45f6-df04-b5d2a51282cc"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 19, done.\n",
            "Counting objects:   5% (1/19)\rCounting objects:  10% (2/19)\rCounting objects:  15% (3/19)\rCounting objects:  21% (4/19)\rCounting objects:  26% (5/19)\rCounting objects:  31% (6/19)\rCounting objects:  36% (7/19)\rCounting objects:  42% (8/19)\rCounting objects:  47% (9/19)\rCounting objects:  52% (10/19)\rCounting objects:  57% (11/19)\rCounting objects:  63% (12/19)\rCounting objects:  68% (13/19)\rCounting objects:  73% (14/19)\rCounting objects:  78% (15/19)\rCounting objects:  84% (16/19)\rCounting objects:  89% (17/19)\rCounting objects:  94% (18/19)\rCounting objects: 100% (19/19)\rCounting objects: 100% (19/19), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:   5% (1/17)\rCompressing objects:  11% (2/17)\rCompressing objects:  17% (3/17)\rCompressing objects:  23% (4/17)\rCompressing objects:  29% (5/17)\rCompressing objects:  35% (6/17)\rCompressing objects:  41% (7/17)\rCompressing objects:  47% (8/17)\rCompressing objects:  52% (9/17)\rCompressing objects:  58% (10/17)\rCompressing objects:  64% (11/17)\rCompressing objects:  70% (12/17)\rCompressing objects:  76% (13/17)\rCompressing objects:  82% (14/17)\rCompressing objects:  88% (15/17)\rCompressing objects:  94% (16/17)\rCompressing objects: 100% (17/17)\rCompressing objects: 100% (17/17), done.\n",
            "Writing objects:   5% (1/18)\rWriting objects:  11% (2/18)\rWriting objects:  16% (3/18)\rWriting objects:  22% (4/18)\rWriting objects:  27% (5/18)\rWriting objects:  33% (6/18)\rWriting objects:  38% (7/18)\rWriting objects:  44% (8/18)\rWriting objects:  50% (9/18)\rWriting objects:  55% (10/18)\rWriting objects:  61% (11/18)\rWriting objects:  66% (12/18)\rWriting objects:  72% (13/18)\rWriting objects:  77% (14/18)\rWriting objects:  83% (15/18)\rWriting objects:  88% (16/18)\rWriting objects:  94% (17/18)\rWriting objects: 100% (18/18)\rWriting objects: 100% (18/18), 741.52 KiB | 15.13 MiB/s, done.\n",
            "Total 18 (delta 0), reused 0 (delta 0), pack-reused 0\n",
            "To https://github.com/sc-AhmedAttia/ObjectDetection.git\n",
            "   fad144c..a5fd253  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wz7emgfdovrK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}